# -*- coding: utf-8 -*-
"""Malicious_Login.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n2hdTgYI2-DhiPjAAf4VuzWOP1dmYhfR
"""

from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir('/content/drive/My Drive/Colab Notebooks/malicious login')

# Commented out IPython magic to ensure Python compatibility.

# %matplotlib inline
import matplotlib
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

datacols = ["duration","protocol_type","service","flag","src_bytes",
    "dst_bytes","land","wrong_fragment","urgent","hot","num_failed_logins",
    "logged_in","num_compromised","root_shell","su_attempted","num_root",
    "num_file_creations","num_shells","num_access_files","num_outbound_cmds",
    "is_host_login","is_guest_login","count","srv_count","serror_rate",
    "srv_serror_rate","rerror_rate","srv_rerror_rate","same_srv_rate",
    "diff_srv_rate","srv_diff_host_rate","dst_host_count","dst_host_srv_count",
    "dst_host_same_srv_rate","dst_host_diff_srv_rate","dst_host_same_src_port_rate",
    "dst_host_srv_diff_host_rate","dst_host_serror_rate","dst_host_srv_serror_rate",
    "dst_host_rerror_rate","dst_host_srv_rerror_rate","class","last_flag"]
training_data = pd.read_table("./KDDTrain+.txt", sep=",", names=datacols)
testing_data=pd.read_table("./KDDTest+.txt", sep=",",names=datacols)
training_data = training_data.iloc[:,:-1]
testing_data = testing_data.iloc[:,:-1]

training_data.head(5)

testing_data.head(5)

from sklearn import preprocessing
label_encoder = preprocessing.LabelEncoder()
training_data = pd.get_dummies(training_data, columns = ["protocol_type","service","flag"])
print(training_data)

#filters for features available
selected_features = ["duration","protocol_type","service","flag","src_bytes",
    "dst_bytes","land","wrong_fragment","urgent","hot","num_failed_logins",
    "logged_in","num_compromised","root_shell","su_attempted","num_root",
    "num_file_creations","num_shells","num_access_files","num_outbound_cmds",
    "is_host_login","is_guest_login","count","srv_count","serror_rate",
    "srv_serror_rate","rerror_rate","srv_rerror_rate","same_srv_rate",
    "diff_srv_rate","srv_diff_host_rate","dst_host_count","dst_host_srv_count",
    "dst_host_same_srv_rate","dst_host_diff_srv_rate","dst_host_same_src_port_rate",
    "dst_host_srv_diff_host_rate","dst_host_serror_rate","dst_host_srv_serror_rate",
    "dst_host_rerror_rate","dst_host_srv_rerror_rate","class"]
training_data=training_data[selected_features]
training_data.head(5)

#print(training_data.head())

print("Training data has {} rows & {} columns".format(training_data.shape[0],training_data.shape[1]))

#print(testing_data.head())

print("Testing data has {} rows & {} columns".format(testing_data.shape[0],testing_data.shape[1]))

ratio = training_data['class'].value_counts()
labels = ratio.index[0], ratio.index[1]
sizes = [ratio.values[0], ratio.values[1]]

figure, axis = plt.subplots()
axis.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
axis.axis('equal')

plt.show()

training_data.drop(['num_outbound_cmds'], axis=1, inplace=True)
testing_data.drop(['num_outbound_cmds'], axis=1, inplace=True)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

cols = training_data.select_dtypes(include=['float64','int64']).columns
sc_train = scaler.fit_transform(training_data.select_dtypes(include=['float64','int64']))
sc_test = scaler.fit_transform(testing_data.select_dtypes(include=['float64','int64']))

sc_traindf = pd.DataFrame(sc_train, columns = cols)
sc_testdf = pd.DataFrame(sc_test, columns = cols)

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()

cattrain = training_data.select_dtypes(include=['object']).copy()
cattest = testing_data.select_dtypes(include=['object']).copy()

traincat = cattrain.apply(encoder.fit_transform)
testcat = cattest.apply(encoder.fit_transform)

enctrain = traincat.drop(['class'], axis=1)
cat_Ytrain = traincat[['class']].copy()

train_x = training_data.drop(['class'], axis=1)
#pd.concat([sc_traindf,enctrain],axis=1)
train_y = training_data['class']
train_x.shape

test_df = testing_data.drop(['class'], axis=1)
test_df.shape

from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFE
import matplotlib.pyplot as plt
import numpy
import warnings
rfc = RandomForestClassifier();
warnings.filterwarnings("ignore")

train_x = np.nan_to_num(train_x)
train_y = np.nan_to_num(train_y)

rfc.fit(train_x, train_y);

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn import metrics as metrics
import itertools
import matplotlib.pyplot as plt
import seaborn
rfc = RandomForestClassifier()

rfe = RFE(rfc, n_features_to_select=10)
rfe = rfe.fit(train_x, train_y)

import pickle
with open('maliciousLogin_model.pkl', 'wb') as file:
  pickle.dump(rfe, file)

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn import metrics as metrics
import itertools
X_train,X_test,Y_train,Y_test = train_test_split(train_x,train_y,train_size=0.60, random_state=2)

model = KNeighborsClassifier(n_jobs=-1)
model.fit(X_train, Y_train);

import pickle
rfe = pickle.load(open('maliciousLogin_model.pkl', 'rb'))

accuracy = metrics.accuracy_score(Y_train, rfe.predict(X_train))
confusion_matrix = metrics.confusion_matrix(Y_train, rfe.predict(X_train))
classification = metrics.classification_report(Y_train, rfe.predict(X_train))


print ("Model Accuracy:" "\n", accuracy)
print ("Confusion matrix:" "\n", confusion_matrix)
print ("Classification report:" "\n", classification)

scores = cross_val_score(rfe, X_train, Y_train, cv=10)
print ("Cross Validation Mean Score:" "\n", scores.mean())

scores = cross_val_score(model, X_train, Y_train, cv=10)
accuracy = metrics.accuracy_score(Y_train, model.predict(X_train))
confusion_matrix = metrics.confusion_matrix(Y_train, model.predict(X_train))
classification = metrics.classification_report(Y_train, model.predict(X_train))

print ("Cross Validation Mean Score:" "\n", scores.mean())
print ("Model Accuracy:" "\n", accuracy)
print ("Confusion matrix:" "\n", confusion_matrix)
print ("Classification report:" "\n", classification)

accuracy = metrics.accuracy_score(Y_test, model.predict(X_test))
confusion_matrix = metrics.confusion_matrix(Y_test, model.predict(X_test))
classification = metrics.classification_report(Y_test, model.predict(X_test))
                                                                     
print ("Model Accuracy:" "\n", accuracy)
print ("Confusion matrix:" "\n", confusion_matrix)
print ("Classification report:" "\n", classification)

prediction = rfe.predict(test_df)
testing_data['prediction'] = prediction
print(testing_data.head())

prediction

ratio = testing_data['prediction'].value_counts()
labels = ratio.index[0], ratio.index[1]
sizes = [ratio.values[0], ratio.values[1]]

figure, axis = plt.subplots()
axis.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
axis.axis('equal')

plt.show()